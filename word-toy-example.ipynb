{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Random Real-Looking Words with Markov Chains\n",
    "\n",
    "Code written by Alex Krentsel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_words() and words_dictionary.json taken from https://github.com/dwyl/english-words\n",
    "\n",
    "import json\n",
    "import os, sys\n",
    "\n",
    "def load_words():\n",
    "    try:\n",
    "        filename = \"words_dictionary.json\"\n",
    "        with open(filename,\"r\") as english_dictionary:\n",
    "            valid_words = json.load(english_dictionary)\n",
    "            return valid_words\n",
    "    except Exception as e:\n",
    "        return str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_dict = load_words()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Approach\n",
    "\n",
    "Same as a Markov chain where a state is just the current letter in the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ denotes start, # denotes finish\n",
    "letters = 'abcdefghijklmnopqrstuvwxyz-$#'\n",
    "char2num = {}\n",
    "num2char = {}\n",
    "for i in range(len(letters)):\n",
    "    char2num[letters[i]] = i\n",
    "    num2char[i] = letters[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry (i, j) is number of times i goes to j\n",
    "trans = np.zeros((len(letters), len(letters)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_INDEX = 27\n",
    "END_INDEX = 28\n",
    "def process_word(word):\n",
    "    trans[START_INDEX, char2num[word[0]]] += 1\n",
    "    trans[char2num[word[-1]], END_INDEX] += 1\n",
    "    for i in range(len(word) - 1):\n",
    "        trans[char2num[word[i]], char2num[word[i+1]]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_dict.keys():\n",
    "    process_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for i in range(trans.shape[0]):\n",
    "    trans[i] = trans[i] / np.sum(trans[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word(T):\n",
    "    new_word = \"\"\n",
    "    row_index = np.random.choice(len(letters), 1, p=T[START_INDEX])[0]\n",
    "    while row_index != END_INDEX:\n",
    "        new_word += num2char[row_index]\n",
    "        row_index = np.random.choice(len(letters), 1, p=T[row_index])[0]\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_words = [generate_word(trans) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rsivinolattrts', 'ckag', 'raleicthiegops', 'd', 'pancarrtinloprsmeratem', 'hride', 'flickskatdicigers', 'm', 'gonag', 'tteoutisppawsustte', 'sty', 'ckochekeylloubtoglideencumedd', 'furicoudaly', 'telelyaranakly', 'rrinthate', 'suniste', 'pmongin', 'elaearepoa', 's', 'cutenohra', 'acaldeseg', 'lblicemar', 'enesior', 'trrisexavery', 'merysk', 's', 'pen', 'shoguricti', 'ioleryon', 'phenderacsdlanisoshlimocom', 'saserwonendl', 'acothurssses', 'ckeraintirn', 'ckicantiratonctar', 'ppliarjerinc', 'terrmalonste', 'py', 'lisscknggedrube', 'mavaeunongoumel', 'rkira', 'a', 'd', 'epls', 'notedrophadrong', 'eanbeniatingysmateniveritapl', 'gly', 'tri', 'vebesolestofeseg', 'amyly', 'ex', 'epond', 'gecleomiontaumble', 'tre', 'flers', 'wc', 'dr', 'veopalasatbidinfosulensetramis', 'wscanonexdeldrmitrerumarg', 'granteroaconowlalm', 'rensstexistrt', 'modacaleracanoisc', 'm', 'asineldelericaveng', 'ti', 'churitopretichakeufaryl', 'sicencothrabod', 's', 'a', 'eppppungermmaveag', 'thlagog', 'apanghe', 'ciscitiopobremiosmondave', 'ors', 'ult', 'me', 'guronenere', 'ol', 'llla', 'seg', 'ereshenfenisog', 'c', 'hy', 'courayinikspesoumnallscymorw', 'tiauchiliat', 'u', 'um', 'tong', 'chaced', 'por', 'r', 'pritesitedasticheecomieclale', 'prinstedaponsmiomimy', 'smeny', 'elelarovacangriabar', 'wslathtty', 'nyngadit', 'gicheremitoroy', 'gysictiountalathoty', 'ubr', 'es']\n"
     ]
    }
   ],
   "source": [
    "print(generated_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Approach\n",
    "Markov chain with each state consisting of the current letter and the previous 2 letters (3 letters total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, val):\n",
    "        self.out = []\n",
    "        self.out_count = []\n",
    "        self.val = val\n",
    "    def next_node(self):\n",
    "        total = sum(self.out_count)\n",
    "        probs = [val / total for val in self.out_count]\n",
    "        index = np.random.choice(len(self.out), 1, p=probs)[0]\n",
    "        return self.out[index]\n",
    "    def add_out(self, key):\n",
    "        if key in self.out:\n",
    "            self.out_count[self.out.index(key)] += 1\n",
    "        else:\n",
    "            self.out.append(key)\n",
    "            self.out_count.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_word(word):\n",
    "    word = '   ' + word + '   '\n",
    "    return [word[i:i+3] for i in range(len(word) - 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_word_node(word, node_dict):\n",
    "    keys = split_word(word)\n",
    "    for i in range(len(keys) - 1):\n",
    "        start_key = keys[i]\n",
    "        next_key = keys[i+1]\n",
    "        if start_key not in node_dict:\n",
    "            node_dict[start_key] = Node(start_key)\n",
    "        node_dict[start_key].add_out(next_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words_dict.keys():\n",
    "    process_word_node(word, node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_node(node_dict):\n",
    "    assert '   ' in node_dict, 'Must have a starting node'\n",
    "    word = ''\n",
    "    node = node_dict[node_dict['   '].next_node()]\n",
    "    while node.val != '   ':\n",
    "        word += node.val[-1]\n",
    "        next_node_key = node.next_node()\n",
    "        node = node_dict[next_node_key]\n",
    "    return word[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bentreor'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_word_node(node_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_word_list = [generate_word_node(node_dict) for _ in range(100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['zonabilizing', 'isobed', 'metriglyptosoiding', 'moul', 'accomethnocarbongourntegocerchful', 'outh', 'cofactive', 'sorbidnexotic', 'scovid', 'unsatid', 'bolity', 'cludelio', 'missoring', 'imosemiteariencephanda', 'mycoidly', 'sperian', 'tanguisia', 'sylidae', 'unverous', 'kiness', 'bency', 'scateronar', 'hies', 'vological', 'crepenaggian', 'pretophization', 'olith', 'premultal', 'jah', 'sing', 'xenomanulicationaquamors', 'mossign', 'goosegmatic', 'globulical', 'rhondersuper', 'incupulmonographysis', 'overcipitercic', 'verm', 'marshippleliclinctuals', 'intron', 'uninizing', 'scutes', 'undes', 'reness', 'obrackles', 'apophophosaultitism', 'coat', 'capetacholourstiline', 'fibrimacross', 'mids', 'cameikh', 'loriacting', 'alaevolute', 'cuff', 'peable', 'poresack', 'interines', 'heremon', 'exsanagirr', 'emmatrix', 'chidropody', 'wood', 'improvoid', 'otomobility', 'cle', 'carancessagain', 'impolympanize', 'few', 'mastiarizing', 'overing', 'prein', 'accents', 'thold', 'curvenes', 'meazer', 'over', 'att', 'vanoned', 'unexpectomationsing', 'sturnflammative', 'lefishly', 'shimbrasseudoaesalizing', 'spira', 'cacoif', 'thrubeeceivitumerototicatic', 'recommunistinen', 'bourocoasty', 'patework', 'brikeite', 'bescopermix', 'priveric', 'hubilible', 'norm', 'kellowe', 'substrichar', 'rhyopy', 'galverradium', 'gigatheose', 'red', 'cerative']\n"
     ]
    }
   ],
   "source": [
    "print(node_word_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
